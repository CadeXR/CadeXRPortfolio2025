(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[175],{272:function(e,t,i){"use strict";i.d(t,{Z:function(){return n}});/**
 * @license lucide-react v0.294.0 - ISC
 *
 * This source code is licensed under the ISC license.
 * See the LICENSE file in the root directory of this source tree.
 */let n=(0,i(2898).Z)("Brain",[["path",{d:"M9.5 2A2.5 2.5 0 0 1 12 4.5v15a2.5 2.5 0 0 1-4.96.44 2.5 2.5 0 0 1-2.96-3.08 3 3 0 0 1-.34-5.58 2.5 2.5 0 0 1 1.32-4.24 2.5 2.5 0 0 1 1.98-3A2.5 2.5 0 0 1 9.5 2Z",key:"1mhkh5"}],["path",{d:"M14.5 2A2.5 2.5 0 0 0 12 4.5v15a2.5 2.5 0 0 0 4.96.44 2.5 2.5 0 0 0 2.96-3.08 3 3 0 0 0 .34-5.58 2.5 2.5 0 0 0-1.32-4.24 2.5 2.5 0 0 0-1.98-3A2.5 2.5 0 0 0 14.5 2Z",key:"1d6s00"}]])},3711:function(e,t,i){"use strict";i.d(t,{Z:function(){return n}});/**
 * @license lucide-react v0.294.0 - ISC
 *
 * This source code is licensed under the ISC license.
 * See the LICENSE file in the root directory of this source tree.
 */let n=(0,i(2898).Z)("ExternalLink",[["path",{d:"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6",key:"a6xqqp"}],["polyline",{points:"15 3 21 3 21 9",key:"mznyad"}],["line",{x1:"10",x2:"21",y1:"14",y2:"3",key:"18c3s4"}]])},6654:function(e,t,i){"use strict";i.d(t,{Z:function(){return n}});/**
 * @license lucide-react v0.294.0 - ISC
 *
 * This source code is licensed under the ISC license.
 * See the LICENSE file in the root directory of this source tree.
 */let n=(0,i(2898).Z)("Target",[["circle",{cx:"12",cy:"12",r:"10",key:"1mglay"}],["circle",{cx:"12",cy:"12",r:"6",key:"1vlfrh"}],["circle",{cx:"12",cy:"12",r:"2",key:"1c9p78"}]])},5750:function(e,t,i){"use strict";i.d(t,{Z:function(){return n}});/**
 * @license lucide-react v0.294.0 - ISC
 *
 * This source code is licensed under the ISC license.
 * See the LICENSE file in the root directory of this source tree.
 */let n=(0,i(2898).Z)("Users",[["path",{d:"M16 21v-2a4 4 0 0 0-4-4H6a4 4 0 0 0-4 4v2",key:"1yyitq"}],["circle",{cx:"9",cy:"7",r:"4",key:"nufk8"}],["path",{d:"M22 21v-2a4 4 0 0 0-3-3.87",key:"kshegd"}],["path",{d:"M16 3.13a4 4 0 0 1 0 7.75",key:"1da9ce"}]])},2369:function(e,t,i){"use strict";i.d(t,{Z:function(){return n}});/**
 * @license lucide-react v0.294.0 - ISC
 *
 * This source code is licensed under the ISC license.
 * See the LICENSE file in the root directory of this source tree.
 */let n=(0,i(2898).Z)("Zap",[["polygon",{points:"13 2 3 14 12 14 11 22 21 10 12 10 13 2",key:"45s27k"}]])},1229:function(e,t,i){Promise.resolve().then(i.bind(i,9807))},9807:function(e,t,i){"use strict";i.r(t),i.d(t,{default:function(){return y}});var n=i(7437),a=i(5251),s=i(272),r=i(2369),o=i(6654),l=i(5750),c=i(3067),d=i(3711),h=i(1396),m=i.n(h);function y(){let e=[{icon:s.Z,title:"Bio-Signal Detection",description:"EKG and EIT systems detect imperceptible muscle contractions"},{icon:r.Z,title:"Real-time Processing",description:"Proprietary algorithms analyze bio-signals instantly"},{icon:o.Z,title:"Full Immersion",description:"Complete VR control through intent and micro-movements"},{icon:l.Z,title:"Universal Compatibility",description:"Works with all immersive software like SteamVR"}];return(0,n.jsxs)("div",{className:"min-h-screen bg-black relative overflow-hidden",children:[(0,n.jsx)("div",{className:"fixed inset-0 bg-gradient-to-br from-purple-900/20 via-black to-pink-900/20"}),(0,n.jsx)(a.E.div,{initial:{opacity:0,y:-20},animate:{opacity:1,y:0},className:"fixed top-8 left-8 z-50",children:(0,n.jsx)(m(),{href:"/",children:(0,n.jsx)(a.E.button,{whileHover:{scale:1.05,x:-5},whileTap:{scale:.95},className:"glass rounded-full p-3 text-white hover:text-primary-400 transition-colors",children:(0,n.jsx)(c.Z,{size:24})})})}),(0,n.jsx)("div",{className:"relative z-10 min-h-screen py-20 px-4",children:(0,n.jsxs)("div",{className:"max-w-6xl mx-auto",children:[(0,n.jsxs)(a.E.div,{initial:{opacity:0,y:30},animate:{opacity:1,y:0},transition:{duration:.8},className:"text-center mb-16",children:[(0,n.jsx)(a.E.div,{initial:{scale:0},animate:{scale:1},transition:{delay:.3,type:"spring"},className:"w-32 h-32 mx-auto mb-8 rounded-full overflow-hidden",children:(0,n.jsx)("img",{src:"/media/ProjectDive.png",alt:"Project Dive",className:"w-full h-full object-cover"})}),(0,n.jsx)("h1",{className:"text-4xl md:text-6xl font-conthrax text-white mb-6",children:(0,n.jsx)("span",{className:"text-gradient-primary",children:"Project Dive"})}),(0,n.jsx)("p",{className:"text-2xl text-gray-300 mb-4",children:"Next Generation VR Immersion"}),(0,n.jsxs)("div",{className:"flex items-center justify-center space-x-4 text-sm text-gray-400",children:[(0,n.jsx)("span",{className:"px-3 py-1 bg-yellow-500/20 text-yellow-400 rounded-full",children:"In Progress"}),(0,n.jsx)("span",{children:"Research"}),(0,n.jsx)("span",{children:"2025"})]})]}),(0,n.jsx)(a.E.div,{initial:{opacity:0,y:30},animate:{opacity:1,y:0},transition:{duration:.8,delay:.4},className:"grid md:grid-cols-2 lg:grid-cols-4 gap-6 mb-16",children:e.map((e,t)=>(0,n.jsxs)(a.E.div,{initial:{opacity:0,y:20},animate:{opacity:1,y:0},transition:{duration:.6,delay:.6+.1*t},className:"glass rounded-xl p-6 text-center hover-lift",children:[(0,n.jsx)("div",{className:"w-12 h-12 bg-gradient-to-r from-purple-500 to-pink-500 rounded-lg flex items-center justify-center mx-auto mb-4",children:(0,n.jsx)(e.icon,{size:24,className:"text-white"})}),(0,n.jsx)("h3",{className:"text-lg font-semibold text-white mb-2",children:e.title}),(0,n.jsx)("p",{className:"text-gray-300 text-sm",children:e.description})]},e.title))}),(0,n.jsx)("div",{className:"space-y-12",children:[{title:"Personal Story",content:"I am working on the designs that can lead to the first generation of a Nervegear-like device. We prototyped an early version at MIT just this January, and I even gave a talk on the prototype and idea at NYU not a few weeks later. I've had conversations with tons of industry professionals I've worked alongside who are interested in seeing a first generation of the device, as well as several large creators in the XR industry I'm already connected with, who would both love to see that prototype and are interested in the project as a whole."},{title:"The Concept",content:"The basic overview is a device that is intended to allow full immersion inside a VR device, 'jacking in' like in The Matrix or Sword Art Online. But instead of waiting 10 years for some sort of outrageously expensive BCI technology or Neuralink chip to somehow be cheap and widespread, the system I am designing uses EKG and EIT kits to detect imperceptible muscle contractions in the legs and arms. These contractions are fed through an algorithm that translates these movements into control inputs that are agnostic with all immersive software (like SteamVR). A lot of the design for this device is based around hardware developed at MIT, found in this research paper: EIT-Kit Research Paper."},{title:"How It Works",content:"The system works by detecting micro-movements in your muscles that you don't even notice you're making. When you think about walking, your leg muscles contract ever so slightly. When you think about grabbing something, your hand muscles respond. These imperceptible contractions are picked up by the EKG and EIT sensors, processed by our proprietary algorithms, and translated into VR control inputs in real-time."},{title:"How It Feels",content:"The best way to describe how the device would feel is imagine laying down in your bed, and very lightly moving the muscles you use to walk. Every time you engage each leg you take a step. Now imagine this across the body, barely flexing a muscle in your arm to lift it, or grabbing door handles by very lightly contracting the same muscle you use to grip. Tying this system with a cheap, basic focus BCI device and eye tracking, I think a fully accessible, completely immersive and futuristic control method is possible."},{title:"Intentional Locomotion",content:"We originally called this system 'Intentional Locomotion' as it's controlling an XR rig entirely out of intent, instead of clunky un-immersive modern control schemes. And a future with a device like this could vastly increase retention in the XR space, going from Meta's recent 'comfort zone' of 20-40 minutes in VR, to hours of perfectly immersive, comfortable VR."},{title:"The Future of VR",content:"Imagine a world where VR isn't just a gaming platform, but a true extension of human experience. Where you can work, socialize, create, and explore in virtual spaces that feel as natural as the physical world. This technology could revolutionize not just gaming, but remote work, education, therapy, and social interaction."}].map((e,t)=>(0,n.jsxs)(a.E.div,{initial:{opacity:0,y:30},animate:{opacity:1,y:0},transition:{duration:.8,delay:.8+.1*t},className:"glass rounded-2xl p-8",children:[(0,n.jsx)("h2",{className:"text-2xl font-semibold text-white mb-6",children:e.title}),(0,n.jsx)("p",{className:"text-gray-300 leading-relaxed text-lg",children:e.content})]},e.title))}),(0,n.jsxs)(a.E.div,{initial:{opacity:0,y:30},animate:{opacity:1,y:0},transition:{duration:.8,delay:1.4},className:"mt-16 glass rounded-2xl p-8",children:[(0,n.jsx)("h2",{className:"text-2xl font-semibold text-white mb-6",children:"Development Status"}),(0,n.jsxs)("div",{className:"grid md:grid-cols-2 gap-8",children:[(0,n.jsxs)("div",{children:[(0,n.jsx)("h3",{className:"text-lg font-semibold text-white mb-3",children:"Current Progress"}),(0,n.jsx)("p",{className:"text-gray-300 leading-relaxed",children:"After successfully prototyping at MIT in January 2024 and presenting at NYU shortly after, we're currently working on the final design pipeline and sourcing hardware components for the next iteration."})]}),(0,n.jsxs)("div",{children:[(0,n.jsx)("h3",{className:"text-lg font-semibold text-white mb-3",children:"Next Steps"}),(0,n.jsxs)("ul",{className:"text-gray-300 space-y-2",children:[(0,n.jsx)("li",{children:"• Finalize hardware component selection"}),(0,n.jsx)("li",{children:"• Optimize bio-signal processing algorithms"}),(0,n.jsx)("li",{children:"• Conduct user testing and feedback"}),(0,n.jsx)("li",{children:"• Prepare for next prototype iteration"})]})]})]})]}),(0,n.jsx)(a.E.div,{initial:{opacity:0,y:30},animate:{opacity:1,y:0},transition:{duration:.8,delay:1.6},className:"mt-12 text-center",children:(0,n.jsxs)(a.E.a,{href:"https://hcie.csail.mit.edu/research/eit-kit/eit-kit.html",target:"_blank",rel:"noopener noreferrer",whileHover:{scale:1.05},whileTap:{scale:.95},className:"btn-neon inline-flex items-center space-x-2",children:[(0,n.jsx)(d.Z,{size:20}),(0,n.jsx)("span",{children:"View EIT-Kit Research Paper"})]})}),(0,n.jsxs)(a.E.div,{initial:{opacity:0,y:30},animate:{opacity:1,y:0},transition:{duration:.8,delay:1.8},className:"text-center mt-16",children:[(0,n.jsx)("p",{className:"text-gray-400 mb-4",children:"Interested in this project or want to collaborate?"}),(0,n.jsx)(m(),{href:"/",children:(0,n.jsx)(a.E.button,{whileHover:{scale:1.05},whileTap:{scale:.95},className:"btn-primary",children:"Get In Touch"})})]})]})})]})}}},function(e){e.O(0,[581,619,971,938,744],function(){return e(e.s=1229)}),_N_E=e.O()}]);